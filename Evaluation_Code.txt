没问题！下面给你一套最小改动、可直接粘到你 main_for_Karen_evaluation.ipynb 的 Evaluate 区的代码块。它只基于你已经落盘的 output/{model_name}_predictions.csv，完成两件事：
	1.	按 VERSION_DATE → CUST_SERIAL_NO 唯一化（customer-level，而不是 campaign-level）；
	2.	把每个 customer 在该 VERSION_DATE 下所有行的 Top-K 候选（3×n 个）合并、按分数排序后取最终 Top-3 且去重（同一产品只保留一次）。

代码会自动优先用 top{K}_weighted_sum 作为打分；如果没这个列，则用 w1*engagement_proba + w2*revenue_increment_proba 计算。
输出：output/{model_name}_customer_level_top3.csv，并打印若干 sanity-check。

⸻

① 读入预测并做基础检查

import pandas as pd
import numpy as np

model_name = "3_REWARD_180925"  # ← 保持和你上面一致
pred_path = f"output/{model_name}_predictions.csv"

pred = pd.read_csv(pred_path, parse_dates=['VERSION_DATE'])
print("== Loaded predictions ==", pred.shape)
print("Columns(sample):", pred.columns[:30].tolist())

# 关键列存在性断言（你的截图里都有这些）
need_cols = ['VERSION_DATE','CUST_SERIAL_NO']
assert all(c in pred.columns for c in need_cols), "缺少 VERSION_DATE 或 CUST_SERIAL_NO"

# 方便下游：统一客户ID类型
pred['CUST_SERIAL_NO'] = pred['CUST_SERIAL_NO'].astype(str)

# 看看每个 VERSION_DATE 的客户覆盖
print("\n# Unique customers per VERSION_DATE:")
print(pred.groupby('VERSION_DATE')['CUST_SERIAL_NO'].nunique().to_string())


⸻

② 把 top1/top2/top3 展平为长表（3n 候选）

TOPK_IN_FILE = 3  # 你的离线预测就是 top1~top3
WEIGHTS = (0.5, 0.5)  # 若没有 weighted_sum 列，用它组合 proba

rows = []
for k in range(1, TOPK_IN_FILE+1):
    # 产品列：通常叫 top1/top2/top3；若你命名不同，这里改一下即可
    prod_col = f"top{k}"
    if prod_col not in pred.columns:
        raise ValueError(f"缺少 {prod_col} 列，请检查 predictions 落盘字段。")

    # 分数字段优先使用 weighted_sum；否则用加权的 proba
    score_col = f"top{k}_weighted_sum"
    if score_col in pred.columns:
        score_series = pred[score_col]
    else:
        # 回退：用 engagement + revenue 的权重加和
        e_col = f"top{k}_engagement_proba"
        r_col = f"top{k}_revenue_increment_proba"
        assert {e_col, r_col}.issubset(pred.columns), f"缺少 {score_col} 也缺少 {e_col}/{r_col}"
        score_series = WEIGHTS[0]*pred[e_col] + WEIGHTS[1]*pred[r_col]

    long_k = pd.DataFrame({
        'VERSION_DATE': pred['VERSION_DATE'],
        'CUST_SERIAL_NO': pred['CUST_SERIAL_NO'],
        'candidate_product': pred[prod_col].astype(str),
        'score': score_series.values,
        'rank_slot': k,  # 来自原始 top1/2/3 的位置，用作次级排序 key
        # 可选：保留原始两柱，便于后续分析
        f'eng_p{k}': pred.get(f"top{k}_engagement_proba", np.nan),
        f'rev_p{k}': pred.get(f"top{k}_revenue_increment_proba", np.nan),
    })
    # 丢掉无产品名/无分数的候选
    long_k = long_k.replace({'candidate_product': {'nan': np.nan}}).dropna(subset=['candidate_product','score'])
    rows.append(long_k)

cands = pd.concat(rows, axis=0, ignore_index=True)
print("\n# Candidate rows (after explode):", cands.shape)
print(cands.head())


⸻

③ 在 customer-date 级别去重并取最终 Top-3（distinct 产品）

# 先按 customer-date、分数降序、原 rank 升序 排好
cands_sorted = cands.sort_values(
    by=['VERSION_DATE','CUST_SERIAL_NO','score','rank_slot'],
    ascending=[True, True, False, True]
)

# 同一 customer-date 下，若同一产品多次出现，只保留分数最高那次
cands_dedup = cands_sorted.drop_duplicates(
    subset=['VERSION_DATE','CUST_SERIAL_NO','candidate_product'],
    keep='first'
)

# 给每个 customer-date 编号 1..K
cands_dedup['rec_pos'] = cands_dedup.groupby(['VERSION_DATE','CUST_SERIAL_NO']).cumcount() + 1

# 仅保留前 K 个（K=3）
FINAL_TOPK = 3
final_topk = cands_dedup[cands_dedup['rec_pos'] <= FINAL_TOPK].copy()

print("\n# Final unique (customer-date) × top3 rows:", final_topk.shape)
print(final_topk.head(10))


⸻

④ 透视成宽表（每个 customer-date 一行，rec1/rec2/rec3）

# 只保留必要列以透视
keep_cols = ['VERSION_DATE','CUST_SERIAL_NO','rec_pos','candidate_product','score']
wide = (final_topk[keep_cols]
        .pivot_table(index=['VERSION_DATE','CUST_SERIAL_NO'],
                     columns='rec_pos',
                     values=['candidate_product','score'],
                     aggfunc='first')
        .sort_index()
       )

# 压平成扁平列名：rec1_product, rec1_score, rec2_product, ...
wide.columns = [f"rec{pos}_{name}" for (name, pos) in wide.columns]
wide = wide.reset_index()

# —— Sanity checks —— #
# 1) 唯一性：每个 VERSION_DATE × CUST_SERIAL_NO 只出现一次
assert wide.duplicated(['VERSION_DATE','CUST_SERIAL_NO']).sum() == 0, "存在重复的 customer-date 行"
# 2) 覆盖率：至少应等于去重前的 unique customer-date 数（若某些客户无候选，可能略小）
uniq_pairs_before = cands[['VERSION_DATE','CUST_SERIAL_NO']].drop_duplicates().shape[0]
print("\n# Unique customer-date BEFORE:", uniq_pairs_before)
print("# Unique customer-date AFTER :", wide.shape[0])

print("\n# Wide sample:")
print(wide.head())

# 落盘
out_path = f"output/{model_name}_customer_level_top3.csv"
wide.to_csv(out_path, index=False)
print(f"\nSaved customer-level Top-3 to: {out_path}")


⸻

⑤ 快速验证（可选，但强烈建议）

# 每个 VERSION_DATE 的 top1 分布（看是否极端倾斜）
vc = (wide
      .groupby(['VERSION_DATE','rec1_candidate_product'])  # 注意列名：是 rec1_candidate_product 还是 rec1_product？
      .size()
      .rename('cnt')
      .reset_index()
     )

# 因上一步列名取决于 pivot 后的命名，兼容处理：
rec1_col = 'rec1_candidate_product' if 'rec1_candidate_product' in wide.columns else 'rec1_product'
tmp = (wide.groupby(['VERSION_DATE', rec1_col]).size()
       .rename('cnt').reset_index()
      )

print("\n# Top-1 distribution by VERSION_DATE (head):")
print(tmp.sort_values(['VERSION_DATE','cnt'], ascending=[True, False]).head(20))

# 断言：每个 customer-date 至少有 1 个推荐（否则你的候选列可能缺失或全空）
assert wide[rec1_col].notna().mean() > 0.99, "有较多 customer-date 没有 rec1；请检查候选构造"

列名提醒
你的落盘里，候选产品列是 top1/top2/top3（字符串，如 Product_Card），分数列是 top{K}_weighted_sum；如果你命名不同，只需在【②】里把 prod_col / score_col 的拼接改一下即可。

⸻

结果你将得到什么？
	•	output/{model_name}_customer_level_top3.csv，每行唯一键是 VERSION_DATE + CUST_SERIAL_NO。列类似于：
	•	rec1_product, rec1_score
	•	rec2_product, rec2_score
	•	rec3_product, rec3_score
	•	这就是基于 customer-level 的去重 Top-3 推荐，可直接喂给后续任何 diversity benefit 的计算逻辑（例如你之后要做的客户层面的收益对比/分层等）。

⸻

为什么这套做法对上了 mentor 的要求？
	•	先 按 VERSION_DATE 再 按客户 聚合：避免把不同时间的同一客户混在一起，符合“先 Version，再 Customer”的唯一化约束。
	•	使用 全量候选池（3×n） 再排序取 Top-3 distinct：不会受 campaign-level 多行的重复限制，也不会被“每行只取自己的 topK”截断。
	•	打分回退机制：有 weighted_sum 用它；没有就用 engagement/revenue 按权重组合，不会再因列缺失而中断。

⸻

如果你希望把 Top-3 限定“互不相同的产品大类”（例如把 Product_Deposit 与 Service_Onboarding 强制不同组），只需在【③】里把
subset=['VERSION_DATE','CUST_SERIAL_NO','candidate_product']
替换为：
subset=['VERSION_DATE','CUST_SERIAL_NO','candidate_group']（先在【②】里多造一列 candidate_group 即可）。

需要我把diversity benefit 的后续计算（客户层收益增量、分层、阈值策略）也接到这个 customer-level 输出上，给你一套可直接跑的指标报表模版吗？